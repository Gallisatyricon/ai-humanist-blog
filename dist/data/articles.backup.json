{
  "articles": [
    {
      "id": "art_001",
      "title": "Efficient Attention Mechanisms in Transformers",
      "url": "https://arxiv.org/abs/2024.01.001",
      "source_type": "arxiv",
      "date": "2024-01-15",
      "summary": "Nouvelle architecture d'attention réduisant la complexité de O(n²) à O(n log n). Tests sur BERT et GPT montrent 40% de réduction en consommation énergétique. Implications pour l'IA frugale.",
      "perspective": "Avancée technique majeure qui ouvre la voie vers des modèles plus démocratiques.",
      "interest_level": 4,
      "primary_domain": "technique",
      "secondary_domains": ["nlp", "green_ai"],
      "concepts": [
        {"id": "attention", "name": "Mécanismes d'attention", "type": "technical", "controversy_level": 0},
        {"id": "efficiency", "name": "Efficacité computationnelle", "type": "methodological", "controversy_level": 1}
      ],
      "tools_mentioned": [
        {"id": "transformers", "name": "Transformers", "type": "framework", "maturity": "stable"},
        {"id": "bert", "name": "BERT", "type": "model", "maturity": "stable"}
      ],
      "complexity_level": "advanced",
      "reading_time": 8,
      "connected_articles": ["art_002", "art_006"],
      "centrality_score": 0.75,
      "author": "Zhang et al."
    },
    {
      "id": "art_002",
      "title": "Bias in Facial Recognition: A European Perspective",
      "url": "https://example.com/bias-facial-recognition",
      "source_type": "academic",
      "date": "2024-01-20",
      "summary": "Étude sur 15 systèmes européens révèle biais systémiques contre minorités ethniques. Taux d'erreur jusqu'à 35% plus élevé. Recommandations réglementaires urgentes.",
      "perspective": "Urgence réglementaire face aux discriminations algorithmiques institutionnalisées.",
      "interest_level": 5,
      "primary_domain": "ethique",
      "secondary_domains": ["bias_fairness", "computer_vision", "regulation"],
      "concepts": [
        {"id": "algorithmic_bias", "name": "Biais algorithmique", "type": "philosophical", "controversy_level": 3},
        {"id": "fairness", "name": "Équité algorithmique", "type": "philosophical", "controversy_level": 2}
      ],
      "tools_mentioned": [
        {"id": "opencv", "name": "OpenCV", "type": "library", "maturity": "stable"}
      ],
      "complexity_level": "intermediate",
      "reading_time": 12,
      "connected_articles": ["art_001", "art_003", "art_005"],
      "centrality_score": 0.85,
      "author": "Dubois et al."
    },
    {
      "id": "art_003",
      "title": "Green AI: Reducing Carbon Footprint in Machine Learning",
      "url": "https://example.com/green-ai",
      "source_type": "blog",
      "date": "2024-02-01",
      "summary": "Stratégies concrètes pour réduire l'empreinte carbone : optimisation modèles, centres de données verts, métriques énergétiques. Retour d'expérience sur 3 projets industriels.",
      "perspective": "La frugalité devient un impératif technique autant qu'éthique.",
      "interest_level": 4,
      "primary_domain": "frugalite",
      "secondary_domains": ["green_ai", "industry_4_0"],
      "concepts": [
        {"id": "sustainability", "name": "Durabilité", "type": "methodological", "controversy_level": 0},
        {"id": "efficiency", "name": "Efficacité computationnelle", "type": "methodological", "controversy_level": 1}
      ],
      "tools_mentioned": [
        {"id": "tensorflow", "name": "TensorFlow", "type": "framework", "maturity": "stable"},
        {"id": "pytorch", "name": "PyTorch", "type": "framework", "maturity": "stable"}
      ],
      "complexity_level": "intermediate",
      "reading_time": 6,
      "connected_articles": ["art_002", "art_004"],
      "centrality_score": 0.6,
      "author": "Martin Green"
    },
    {
      "id": "art_004",
      "title": "Explainable AI in Healthcare: Beyond Black Boxes",
      "url": "https://example.com/xai-healthcare",
      "source_type": "academic",
      "date": "2024-02-10",
      "summary": "Méthodes d'explicabilité adaptées au diagnostic médical. Étude comparative LIME, SHAP, attention maps sur 1000 cas cliniques. Impact sur confiance des praticiens.",
      "perspective": "Transparence algorithmique condition sine qua non de l'acceptation médicale.",
      "interest_level": 4,
      "primary_domain": "usage_professionnel",
      "secondary_domains": ["healthcare", "transparency", "computer_vision"],
      "concepts": [
        {"id": "explainability", "name": "Explicabilité", "type": "methodological", "controversy_level": 1},
        {"id": "trust", "name": "Confiance algorithmique", "type": "philosophical", "controversy_level": 2}
      ],
      "tools_mentioned": [
        {"id": "lime", "name": "LIME", "type": "library", "maturity": "stable"},
        {"id": "shap", "name": "SHAP", "type": "library", "maturity": "stable"}
      ],
      "complexity_level": "advanced",
      "reading_time": 10,
      "connected_articles": ["art_003", "art_005"],
      "centrality_score": 0.7,
      "author": "Dr. Sarah Johnson"
    },
    {
      "id": "art_005",
      "title": "The Philosophy of AI Consciousness: Questioning Machine Sentience",
      "url": "https://example.com/ai-consciousness",
      "source_type": "blog",
      "date": "2024-02-15",
      "summary": "Analyse philosophique des questions de conscience artificielle. Déconstruction des tests de Turing modernes. Implications éthiques si l'IA développe une forme de sentience.",
      "perspective": "La question de la conscience machine redéfinit notre rapport à l'intelligence.",
      "interest_level": 3,
      "primary_domain": "philosophie",
      "secondary_domains": ["society"],
      "concepts": [
        {"id": "consciousness", "name": "Conscience artificielle", "type": "philosophical", "controversy_level": 3},
        {"id": "sentience", "name": "Sentience machine", "type": "philosophical", "controversy_level": 3},
        {"id": "turing_test", "name": "Test de Turing", "type": "methodological", "controversy_level": 1}
      ],
      "tools_mentioned": [],
      "complexity_level": "advanced",
      "reading_time": 15,
      "connected_articles": ["art_002", "art_004", "art_006"],
      "centrality_score": 0.55,
      "author": "Prof. Elena Vasquez"
    },
    {
      "id": "art_006",
      "title": "Large Language Models in Academic Research: Productivity vs Integrity",
      "url": "https://example.com/llm-academic",
      "source_type": "academic",
      "date": "2024-02-20",
      "summary": "Impact des LLM sur recherche académique : 67% gain productivité mais questions intégrité intellectuelle. Propositions de guidelines pour usage éthique.",
      "perspective": "Les LLM transforment la recherche mais exigent un nouveau cadre déontologique.",
      "interest_level": 5,
      "primary_domain": "recherche",
      "secondary_domains": ["nlp", "education", "accountability"],
      "concepts": [
        {"id": "academic_integrity", "name": "Intégrité académique", "type": "philosophical", "controversy_level": 2},
        {"id": "productivity", "name": "Productivité recherche", "type": "methodological", "controversy_level": 0}
      ],
      "tools_mentioned": [
        {"id": "gpt", "name": "GPT", "type": "model", "maturity": "stable"},
        {"id": "claude", "name": "Claude", "type": "model", "maturity": "stable"}
      ],
      "complexity_level": "intermediate",
      "reading_time": 7,
      "connected_articles": ["art_001", "art_005"],
      "centrality_score": 0.8,
      "author": "Research Ethics Consortium"
    }
  ]
}